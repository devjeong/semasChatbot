# LM Studio í†µê³„ ì „ì†¡ API ê¸°ëŠ¥ëª…ì„¸ì„œ

## ğŸ“‹ ê°œìš”

LM Studio ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ LLM ì‘ë‹µì„ ë°›ì€ í›„, ì‘ë‹µì— ëŒ€í•œ í†µê³„ ì •ë³´ë¥¼ ì„œë²„ë¡œ ì „ì†¡í•˜ëŠ” ê¸°ëŠ¥ì„ êµ¬í˜„í•©ë‹ˆë‹¤.

### ëª©ì 
- LM Studio ëª¨ë¸ ì‚¬ìš©ëŸ‰ ì¶”ì  ë° ë¶„ì„
- ì‚¬ìš©ìë³„ ëª¨ë¸ ì‚¬ìš© í†µê³„ ìˆ˜ì§‘
- ì„œë²„ì—ì„œ ì¤‘ì•™ ì§‘ì¤‘ì‹ í†µê³„ ê´€ë¦¬

### ë²”ìœ„
- LM Studio ëª¨ë¸ ì‚¬ìš© ì‹œì—ë§Œ ë™ì‘
- ì‘ë‹µ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ í†µê³„ ì „ì†¡
- ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ ì‚¬ìš©ì ê²½í—˜ì— ì˜í–¥ ì—†ìŒ

---

## ğŸ¯ ìš”êµ¬ì‚¬í•­

### ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­

1. **í†µê³„ ì •ë³´ ìˆ˜ì§‘**
   - ì‚¬ìš©ì ì•„ì´ë”” (userId)
   - ì‚¬ìš© ëª¨ë¸ëª… (modelId)
   - ì…ë ¥ í† í° ìˆ˜ (inputTokens)
   - ì¶œë ¥ í† í° ìˆ˜ (outputTokens)
   - ì´ í† í° ìˆ˜ (totalTokens)
   - ì‘ë‹µ ì‹œê°„ (responseTime, ë°€ë¦¬ì´ˆ)

2. **ì„œë²„ API í˜¸ì¶œ**
   - HTTP POST ë°©ì‹
   - JSON í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ì „ì†¡
   - ì„œë²„ IPëŠ” ì„¤ì • ê°€ëŠ¥
   - ë¹„ë™ê¸° ì²˜ë¦¬ (ì‚¬ìš©ì ê²½í—˜ì— ì˜í–¥ ì—†ìŒ)

3. **ì—ëŸ¬ ì²˜ë¦¬**
   - ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œ ì¬ì‹œë„ (ìµœëŒ€ 3íšŒ)
   - ì‹¤íŒ¨í•´ë„ ì‚¬ìš©ìì—ê²Œ ì˜í–¥ ì—†ìŒ (ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬)
   - ë¡œê¹…ì„ í†µí•œ ë””ë²„ê¹… ì§€ì›

---

## ğŸ“ API ìŠ¤í™

### ì—”ë“œí¬ì¸íŠ¸

**URL**: `{ì„œë²„_IP}/api/lm-studio/stats`

**Method**: `POST`

**Content-Type**: `application/json`

### ìš”ì²­ ë³¸ë¬¸ (Request Body)

```json
{
  "userId": 123,
  "modelId": "llama-3.1-8b-instruct",
  "inputTokens": 150,
  "outputTokens": 250,
  "totalTokens": 400,
  "responseTime": 1250
}
```

#### í•„ë“œ ì„¤ëª…

| í•„ë“œëª… | íƒ€ì… | í•„ìˆ˜ | ì„¤ëª… |
|--------|------|------|------|
| `userId` | integer | âœ… | ë¡œê·¸ì¸í•œ ì‚¬ìš©ì ID (ë¡œê·¸ì¸í•˜ì§€ ì•Šì€ ê²½ìš° null) |
| `modelId` | string | âœ… | ì‚¬ìš©í•œ LM Studio ëª¨ë¸ ID |
| `inputTokens` | integer | âœ… | ì…ë ¥ í† í° ìˆ˜ |
| `outputTokens` | integer | âœ… | ì¶œë ¥ í† í° ìˆ˜ |
| `totalTokens` | integer | âœ… | ì´ í† í° ìˆ˜ (inputTokens + outputTokens) |
| `responseTime` | integer | âœ… | ì‘ë‹µ ì‹œê°„ (ë°€ë¦¬ì´ˆ) |

### ì‘ë‹µ (Response)

#### ì„±ê³µ ì‘ë‹µ (HTTP 200 OK)

```json
{
  "success": true,
  "message": "í†µê³„ ì •ë³´ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."
}
```

#### ì‹¤íŒ¨ ì‘ë‹µ (HTTP 400 Bad Request)

```json
{
  "success": false,
  "message": "ì˜ëª»ëœ ìš”ì²­ í˜•ì‹ì…ë‹ˆë‹¤.",
  "error": "í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."
}
```

#### ì‹¤íŒ¨ ì‘ë‹µ (HTTP 500 Internal Server Error)

```json
{
  "success": false,
  "message": "ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
  "error": "ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"
}
```

---

## ğŸ”§ êµ¬í˜„ ê³„íš

### Phase 1: ë°ì´í„° ëª¨ë¸ ì„¤ê³„

#### Task 1.1: LM Studio í†µê³„ ë°ì´í„° ëª¨ë¸ ìƒì„±

```kotlin
/**
 * LM Studio í†µê³„ ì •ë³´ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤
 */
data class LmStudioStats(
    val userId: Int?,
    val modelId: String,
    val inputTokens: Int,
    val outputTokens: Int,
    val totalTokens: Int,
    val responseTime: Long  // ë°€ë¦¬ì´ˆ
)
```

**íŒŒì¼ ìœ„ì¹˜**: `src/main/kotlin/org/dev/semaschatbot/LmStudioStats.kt`

---

### Phase 2: LM Studio API ì‘ë‹µ íŒŒì‹± ê°œì„ 

#### Task 2.1: LmStudioClient ì‘ë‹µ íŒŒì‹± ê°œì„ 

**ëª©í‘œ**: LM Studio API ì‘ë‹µì—ì„œ í† í° ì •ë³´ì™€ ì‘ë‹µ ì‹œê°„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

**í˜„ì¬ ë¬¸ì œì **:
- `sendChatRequest()` ë©”ì„œë“œê°€ í† í° ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì§€ ì•ŠìŒ
- ì‘ë‹µ ì‹œê°„ì„ ì¸¡ì •í•˜ì§€ ì•ŠìŒ
- `usage` í•„ë“œë¥¼ íŒŒì‹±í•˜ì§€ ì•ŠìŒ

**ê°œì„  ë°©ì•ˆ**:

1. **ì‘ë‹µ ë°ì´í„° í´ë˜ìŠ¤ ìƒì„±**
```kotlin
/**
 * LM Studio API ì‘ë‹µì„ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤
 */
data class LmStudioResponse(
    val content: String,
    val usage: LmStudioUsage?,
    val modelId: String
)

data class LmStudioUsage(
    val promptTokens: Int,
    val completionTokens: Int,
    val totalTokens: Int
)
```

2. **sendChatRequest ë©”ì„œë“œ ìˆ˜ì •**
```kotlin
/**
 * LM Studio APIì— ì±„íŒ… ìš”ì²­ì„ ë³´ë‚´ê³  ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
 * @param userMessage ì‚¬ìš©ì ì…ë ¥ ë©”ì‹œì§€
 * @param systemMessage ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
 * @param modelId ì‚¬ìš©í•  LLM ëª¨ë¸ì˜ ID
 * @return LmStudioResponse ê°ì²´ (í† í° ì •ë³´ í¬í•¨)
 */
fun sendChatRequest(
    userMessage: String, 
    systemMessage: String, 
    modelId: String = "default-model"
): LmStudioResponse? {
    val startTime = System.currentTimeMillis()
    
    // ... ê¸°ì¡´ ìš”ì²­ ë¡œì§ ...
    
    val responseBody = response.body?.string() ?: return null
    val jsonResponse = gson.fromJson(responseBody, JsonObject::class.java)
    
    val choices = jsonResponse.getAsJsonArray("choices")
    val content = if (choices.size() > 0) {
        choices.get(0).asJsonObject
            .getAsJsonObject("message")
            .get("content").asString
    } else {
        return null
    }
    
    // usage ì •ë³´ ì¶”ì¶œ
    val usage = jsonResponse.getAsJsonObject("usage")?.let {
        LmStudioUsage(
            promptTokens = it.get("prompt_tokens")?.asInt ?: 0,
            completionTokens = it.get("completion_tokens")?.asInt ?: 0,
            totalTokens = it.get("total_tokens")?.asInt ?: 0
        )
    }
    
    val responseTime = System.currentTimeMillis() - startTime
    
    return LmStudioResponse(
        content = content,
        usage = usage,
        modelId = modelId
    )
}
```

**íŒŒì¼ ìœ„ì¹˜**: `src/main/kotlin/org/dev/semaschatbot/LmStudioClient.kt` (ìˆ˜ì •)

---

### Phase 3: í†µê³„ ì „ì†¡ API í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„

#### Task 3.1: LmStudioStatsApiClient í´ë˜ìŠ¤ ìƒì„±

**ëª©í‘œ**: ì„œë²„ë¡œ í†µê³„ ì •ë³´ë¥¼ ì „ì†¡í•˜ëŠ” API í´ë¼ì´ì–¸íŠ¸ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.

**êµ¬í˜„ ë‚´ìš©**:

```kotlin
/**
 * LM Studio í†µê³„ ì •ë³´ë¥¼ ì„œë²„ë¡œ ì „ì†¡í•˜ëŠ” API í´ë¼ì´ì–¸íŠ¸
 */
class LmStudioStatsApiClient(
    private var serverBaseUrl: String = "http://192.168.18.53"
) {
    private val client = OkHttpClient.Builder()
        .connectTimeout(10, TimeUnit.SECONDS)
        .readTimeout(10, TimeUnit.SECONDS)
        .writeTimeout(10, TimeUnit.SECONDS)
        .build()
    
    private val gson = Gson()
    
    /**
     * ì„œë²„ ê¸°ë³¸ URL ì„¤ì •
     */
    fun setServerBaseUrl(url: String) {
        serverBaseUrl = url.trim().removeSuffix("/")
    }
    
    /**
     * LM Studio í†µê³„ ì •ë³´ë¥¼ ì„œë²„ë¡œ ì „ì†¡í•©ë‹ˆë‹¤.
     * 
     * @param stats í†µê³„ ì •ë³´
     * @return ì „ì†¡ ì„±ê³µ ì—¬ë¶€
     */
    fun sendStats(stats: LmStudioStats): Boolean {
        return try {
            val requestBodyMap = mapOf(
                "userId" to (stats.userId ?: 0),
                "modelId" to stats.modelId,
                "inputTokens" to stats.inputTokens,
                "outputTokens" to stats.outputTokens,
                "totalTokens" to stats.totalTokens,
                "responseTime" to stats.responseTime
            )
            
            val requestBodyJson = gson.toJson(requestBodyMap)
            val request = Request.Builder()
                .url("$serverBaseUrl/api/lm-studio/stats")
                .post(RequestBody.create("application/json".toMediaTypeOrNull(), requestBodyJson))
                .build()
            
            client.newCall(request).execute().use { response ->
                response.isSuccessful
            }
        } catch (e: Exception) {
            println("[LmStudioStatsApiClient] í†µê³„ ì „ì†¡ ì‹¤íŒ¨: ${e.message}")
            false
        }
    }
    
    /**
     * LM Studio í†µê³„ ì •ë³´ë¥¼ ì„œë²„ë¡œ ì „ì†¡í•©ë‹ˆë‹¤. (ë¹„ë™ê¸°, ì¬ì‹œë„ í¬í•¨)
     * 
     * @param stats í†µê³„ ì •ë³´
     * @param maxRetries ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ (ê¸°ë³¸ê°’: 3)
     */
    fun sendStatsAsync(stats: LmStudioStats, maxRetries: Int = 3) {
        Thread {
            var success = false
            for (attempt in 1..maxRetries) {
                success = sendStats(stats)
                if (success) {
                    println("[LmStudioStatsApiClient] í†µê³„ ì „ì†¡ ì„±ê³µ (ì‹œë„ $attempt)")
                    break
                } else {
                    if (attempt < maxRetries) {
                        Thread.sleep(1000 * attempt) // ì§€ìˆ˜ ë°±ì˜¤í”„
                    }
                }
            }
            if (!success) {
                println("[LmStudioStatsApiClient] í†µê³„ ì „ì†¡ ì‹¤íŒ¨ (ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨)")
            }
        }.start()
    }
}
```

**íŒŒì¼ ìœ„ì¹˜**: `src/main/kotlin/org/dev/semaschatbot/LmStudioStatsApiClient.kt`

---

### Phase 4: ChatService í†µí•©

#### Task 4.1: ChatServiceì— í†µê³„ ì „ì†¡ ë¡œì§ ì¶”ê°€

**ëª©í‘œ**: LM Studio ëª¨ë¸ ì‚¬ìš© ì‹œ ì‘ë‹µ ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ í†µê³„ë¥¼ ì „ì†¡í•©ë‹ˆë‹¤.

**êµ¬í˜„ ìœ„ì¹˜**: `ChatService.kt`

**ìˆ˜ì • ë‚´ìš©**:

1. **LmStudioStatsApiClient ì¸ìŠ¤í„´ìŠ¤ ì¶”ê°€**
```kotlin
private val lmStudioStatsApiClient = LmStudioStatsApiClient()
```

2. **LM Studio ì‘ë‹µ ì²˜ë¦¬ ì‹œ í†µê³„ ì „ì†¡**
```kotlin
// LM Studio API í˜¸ì¶œ ì™„ë£Œ ì‹œ
onComplete = {
    ApplicationManager.getApplication().invokeLater {
        loadingIndicator?.isVisible = false
        
        val responseTime = System.currentTimeMillis() - startTime
        val responseText = accumulatedResponse.toString()
        
        // LM Studio ì‘ë‹µì—ì„œ í† í° ì •ë³´ ì¶”ì¶œ (ì‘ë‹µ ê°œì„  í›„)
        val estimatedInputTokens = prompt.length / 4
        val estimatedOutputTokens = responseText.length / 4
        
        // í†µê³„ ì •ë³´ ìƒì„±
        val currentUserId = try {
            userService.getCurrentUser()?.id
        } catch (e: Exception) {
            null
        }
        
        val stats = LmStudioStats(
            userId = currentUserId,
            modelId = modelId,
            inputTokens = estimatedInputTokens,
            outputTokens = estimatedOutputTokens,
            totalTokens = estimatedInputTokens + estimatedOutputTokens,
            responseTime = responseTime
        )
        
        // ë¹„ë™ê¸°ë¡œ í†µê³„ ì „ì†¡ (ì‚¬ìš©ì ê²½í—˜ì— ì˜í–¥ ì—†ìŒ)
        lmStudioStatsApiClient.sendStatsAsync(stats)
        
        // ê¸°ì¡´ ì‚¬ìš©ëŸ‰ ì¸¡ì • ë¡œì§
        userService.recordApiCall(true, responseTime)
        userService.recordTokens(estimatedInputTokens, estimatedOutputTokens)
        
        // ... ê¸°ì¡´ ë¡œì§ ê³„ì† ...
    }
}
```

3. **ì‘ì—… ëª¨ë“œì—ì„œë„ í†µê³„ ì „ì†¡**
```kotlin
// executeTaskWithSelectedModelì—ì„œ LM Studio ì‚¬ìš© ì‹œ
val result = if (isGeminiModel(modelId)) {
    // Gemini API í˜¸ì¶œ
    // ...
} else {
    // LM Studio API í˜¸ì¶œ
    val startTime = System.currentTimeMillis()
    val lmResponse = apiClient.sendChatRequest(
        userMessage = prompt,
        systemMessage = systemMessage,
        modelId = modelId
    )
    
    if (lmResponse != null) {
        val responseTime = System.currentTimeMillis() - startTime
        
        // í†µê³„ ì •ë³´ ìƒì„± ë° ì „ì†¡
        val stats = LmStudioStats(
            userId = currentUserId,
            modelId = modelId,
            inputTokens = lmResponse.usage?.promptTokens ?: (prompt.length / 4),
            outputTokens = lmResponse.usage?.completionTokens ?: (lmResponse.content.length / 4),
            totalTokens = lmResponse.usage?.totalTokens ?: ((prompt.length + lmResponse.content.length) / 4),
            responseTime = responseTime
        )
        
        // ë¹„ë™ê¸°ë¡œ í†µê³„ ì „ì†¡
        lmStudioStatsApiClient.sendStatsAsync(stats)
        
        lmResponse.content
    } else {
        "ì˜¤ë¥˜: LM Studio API ì‘ë‹µì´ nullì…ë‹ˆë‹¤."
    }
}
```

---

## ğŸ“Š ë°ì´í„° íë¦„

### 1. LM Studio API í˜¸ì¶œ
```
ì‚¬ìš©ì ì…ë ¥ â†’ ChatService â†’ LmStudioClient.sendChatRequest()
â†’ LM Studio ì„œë²„ â†’ ì‘ë‹µ ìˆ˜ì‹  (í† í° ì •ë³´ í¬í•¨)
```

### 2. í†µê³„ ì •ë³´ ìˆ˜ì§‘
```
ì‘ë‹µ ìˆ˜ì‹  â†’ í† í° ì •ë³´ ì¶”ì¶œ â†’ ì‘ë‹µ ì‹œê°„ ê³„ì‚° â†’ LmStudioStats ê°ì²´ ìƒì„±
```

### 3. í†µê³„ ì „ì†¡
```
LmStudioStats ê°ì²´ â†’ LmStudioStatsApiClient.sendStatsAsync()
â†’ ì„œë²„ API í˜¸ì¶œ â†’ ì„±ê³µ/ì‹¤íŒ¨ ì²˜ë¦¬
```

---

## ğŸ” ìƒì„¸ êµ¬í˜„ ì‚¬í•­

### 1. í† í° ì •ë³´ ì¶”ì¶œ

#### ë°©ë²• 1: API ì‘ë‹µì—ì„œ ì¶”ì¶œ (ê¶Œì¥)
LM Studio API ì‘ë‹µì— `usage` í•„ë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ” ê²½ìš°:

```json
{
  "choices": [...],
  "usage": {
    "prompt_tokens": 150,
    "completion_tokens": 250,
    "total_tokens": 400
  }
}
```

#### ë°©ë²• 2: ì¶”ì • (í´ë°±)
API ì‘ë‹µì— `usage` í•„ë“œê°€ ì—†ëŠ” ê²½ìš°:
- ì…ë ¥ í† í°: `prompt.length / 4` (ëŒ€ëµì ì¸ ì¶”ì •)
- ì¶œë ¥ í† í°: `response.length / 4` (ëŒ€ëµì ì¸ ì¶”ì •)
- ì´ í† í°: `inputTokens + outputTokens`

### 2. ì‘ë‹µ ì‹œê°„ ì¸¡ì •

```kotlin
val startTime = System.currentTimeMillis()
// API í˜¸ì¶œ
val response = apiClient.sendChatRequest(...)
val responseTime = System.currentTimeMillis() - startTime
```

### 3. ì„œë²„ URL ì„¤ì •

ì„œë²„ IPëŠ” ì„¤ì • ê°€ëŠ¥í•˜ë„ë¡ êµ¬í˜„:
- ê¸°ë³¸ê°’: `http://192.168.18.53`
- ì„¤ì • íŒŒì¼ ë˜ëŠ” UIë¥¼ í†µí•´ ë³€ê²½ ê°€ëŠ¥
- `LmStudioStatsApiClient.setServerBaseUrl()` ë©”ì„œë“œ ì‚¬ìš©

### 4. ì—ëŸ¬ ì²˜ë¦¬

- ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: ì¬ì‹œë„ (ìµœëŒ€ 3íšŒ, ì§€ìˆ˜ ë°±ì˜¤í”„)
- ì„œë²„ ì˜¤ë¥˜: ë¡œê¹…ë§Œ í•˜ê³  ì‚¬ìš©ìì—ê²Œ ì˜í–¥ ì—†ìŒ
- íŒŒì‹± ì˜¤ë¥˜: ì¶”ì •ê°’ ì‚¬ìš©

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ê³„íš

### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

1. **LmStudioStats ë°ì´í„° í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸**
   - ê°ì²´ ìƒì„± ë° í•„ë“œ ê²€ì¦
   - null ê°’ ì²˜ë¦¬

2. **LmStudioStatsApiClient í…ŒìŠ¤íŠ¸**
   - ì„œë²„ URL ì„¤ì •
   - í†µê³„ ì „ì†¡ ì„±ê³µ/ì‹¤íŒ¨ ì¼€ì´ìŠ¤
   - ì¬ì‹œë„ ë¡œì§ ê²€ì¦

3. **LmStudioClient ì‘ë‹µ íŒŒì‹± í…ŒìŠ¤íŠ¸**
   - usage ì •ë³´ ì¶”ì¶œ
   - í† í° ì •ë³´ íŒŒì‹±
   - í´ë°± ë¡œì§ ê²€ì¦

### í†µí•© í…ŒìŠ¤íŠ¸

1. **ì „ì²´ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸**
   - LM Studio API í˜¸ì¶œ â†’ í†µê³„ ìˆ˜ì§‘ â†’ ì„œë²„ ì „ì†¡
   - ì‹¤ì œ ì„œë²„ APIì™€ì˜ í†µì‹  ê²€ì¦

2. **ì—ëŸ¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸**
   - ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ì‹œ ì¬ì‹œë„
   - ì„œë²„ ì˜¤ë¥˜ ì‹œ ì‚¬ìš©ì ê²½í—˜ ì˜í–¥ ì—†ìŒ í™•ì¸

---

## ğŸ“ êµ¬í˜„ ìš°ì„ ìˆœìœ„

### High Priority
1. **Phase 1**: ë°ì´í„° ëª¨ë¸ ì„¤ê³„
2. **Phase 2**: LM Studio API ì‘ë‹µ íŒŒì‹± ê°œì„ 
3. **Phase 3**: í†µê³„ ì „ì†¡ API í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„

### Medium Priority
4. **Phase 4**: ChatService í†µí•©

---

## ğŸ”„ ê¸°ì¡´ ì½”ë“œì™€ì˜ í˜¸í™˜ì„±

### ì£¼ì˜ì‚¬í•­

1. **LmStudioClient.sendChatRequest() ë°˜í™˜ íƒ€ì… ë³€ê²½**
   - í˜„ì¬: `String?` ë°˜í™˜
   - ë³€ê²½ í›„: `LmStudioResponse?` ë°˜í™˜
   - **í˜¸í™˜ì„± ìœ ì§€**: ê¸°ì¡´ ì½”ë“œì—ì„œ `response.content`ë¡œ ì ‘ê·¼ ê°€ëŠ¥

2. **ê¸°ì¡´ ì‚¬ìš©ëŸ‰ ì¸¡ì • ë¡œì§ ìœ ì§€**
   - `userService.recordApiCall()` ê³„ì† ì‚¬ìš©
   - `userService.recordTokens()` ê³„ì† ì‚¬ìš©
   - ìƒˆë¡œìš´ í†µê³„ ì „ì†¡ì€ ì¶”ê°€ ê¸°ëŠ¥ìœ¼ë¡œ êµ¬í˜„

---

## ğŸ“… ì˜ˆìƒ ì‘ì—… ì‹œê°„

- **Phase 1**: 1ì‹œê°„
- **Phase 2**: 2-3ì‹œê°„
- **Phase 3**: 2-3ì‹œê°„
- **Phase 4**: 2-3ì‹œê°„

**ì´ ì˜ˆìƒ ì‹œê°„**: 7-10ì‹œê°„

---

## ğŸ” ë¦¬ìŠ¤í¬ ë° ëŒ€ì‘ ë°©ì•ˆ

### ë¦¬ìŠ¤í¬ 1: LM Studio API ì‘ë‹µì— usage í•„ë“œê°€ ì—†ëŠ” ê²½ìš°
- **ëŒ€ì‘**: ì¶”ì •ê°’ ì‚¬ìš© (ë¬¸ìì—´ ê¸¸ì´ ê¸°ë°˜)
- **ê²€ì¦**: ë‹¤ì–‘í•œ LM Studio ëª¨ë¸ì—ì„œ í…ŒìŠ¤íŠ¸

### ë¦¬ìŠ¤í¬ 2: ì„œë²„ APIê°€ ì¤€ë¹„ë˜ì§€ ì•Šì€ ê²½ìš°
- **ëŒ€ì‘**: ì‹¤íŒ¨í•´ë„ ì‚¬ìš©ì ê²½í—˜ì— ì˜í–¥ ì—†ìŒ (ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬)
- **ê²€ì¦**: ì„œë²„ API êµ¬í˜„ ì „ì—ë„ í´ë¼ì´ì–¸íŠ¸ ì½”ë“œëŠ” ë™ì‘ ê°€ëŠ¥

### ë¦¬ìŠ¤í¬ 3: ë„¤íŠ¸ì›Œí¬ ì§€ì—°ìœ¼ë¡œ ì¸í•œ ì„±ëŠ¥ ì €í•˜
- **ëŒ€ì‘**: ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ ì‚¬ìš©ì ê²½í—˜ì— ì˜í–¥ ì—†ìŒ
- **ê²€ì¦**: íƒ€ì„ì•„ì›ƒ ì„¤ì • ë° ì¬ì‹œë„ ë¡œì§ ê²€ì¦

---

## ğŸ“š ì°¸ê³  ìë£Œ

- ê¸°ì¡´ `AuthApiClient.kt` êµ¬ì¡° ì°¸ê³ 
- ê¸°ì¡´ `LmStudioClient.kt` ì‘ë‹µ íŒŒì‹± ë¡œì§ ì°¸ê³ 
- OpenAI API ìŠ¤í™ (LM StudioëŠ” OpenAI í˜¸í™˜)

---

**ì‘ì„±ì¼**: 2024-01-XX
**ì‘ì„±ì**: AI Assistant
**ë²„ì „**: 1.0

